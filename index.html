<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Navigating the Broader Impacts of AI Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="homepage is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">

					<!-- Inner -->
						<div class="inner">
							<header>
								<h1 class="title"><a href="index.html" id="logo">Navigating <br /> the Broader Impacts <br /> of AI Research</a></h1>
								<hr />
								<h2 class="subtitle">NeurIPS 2020 Workshop <br /> December 12, 2020</h2>
							</header>
							<footer>
								<a href="#intro" class="button circled">More</a>
							</footer>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<!-- <li>
									<a href="#">Dropdown</a>
									<ul>
										<li><a href="#">Lorem ipsum dolor</a></li>
										<li><a href="#">Magna phasellus</a></li>
										<li><a href="#">Etiam dolore nisl</a></li>
										<li>
											<a href="#">And a submenu &hellip;</a>
											<ul>
												<li><a href="#">Lorem ipsum dolor</a></li>
												<li><a href="#">Phasellus consequat</a></li>
												<li><a href="#">Magna phasellus</a></li>
												<li><a href="#">Etiam dolore nisl</a></li>
											</ul>
										</li>
										<li><a href="#">Veroeros feugiat</a></li>
									</ul>
								</li> -->
								<li><a href="#intro">About</a></li>
								<li><a href="#Agenda">Agenda</a></li>
								<li><a href="#Papers">Papers</a></li>
								<li><a href="#People">People</a></li>
					
							</ul>
						</nav>

				</div>

			<!-- Banner
				<section id="banner">
					<header>
						<h2>Hi. You're looking at <strong>Helios</strong>.</h2>
						<p></p>
						
					</header>
				</section> -->

			

			<!-- Main -->
				<div id="intro" class="wrapper style1">

					<article id="main" class="container special">
						<!-- <a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a> -->
						<header>
							<p>
								This workshop is a part of the <a href="https://nips.cc/">2020 Neural Information Processing Systems conference</a> (NeurIPS), and <a href="https://neurips.cc/Conferences/2020/Schedule?showEvent=16144">the event</a> will be held <em>virtually</em> along with other workshops on <strong>December 12, 2020</strong>.
							</p>
						</header>
						<p>Following growing concerns with both harmful research impact and research conduct in computer science <a href="https://acm-fca.org/2018/03/29/negativeimpacts/">[1]</a>, including concerns with research published at NeurIPS <a href="https://twitter.com/alexhanna/status/1205214184679649280">[2]</a> <a href="https://twitter.com/VaroonMathur/status/1205247456428134402">[3]</a> <a href="https://youtu.be/vpPpwa7W93I?t=554">[4]</a>, this year’s conference introduced two new mechanisms for ethical oversight: a requirement that authors include a “broader impact statement” in their paper submissions and additional evaluation criteria asking paper reviewers to identify any potential ethical issues with the submissions <a href="https://medium.com/@NeurIPSConf/getting-started-with-neurips-2020-e350f9b39c28">[5]</a> <a href="https://medium.com/@GovAI/a-guide-to-writing-the-neurips-impact-statement-4293b723f832">[6]</a>.</p>
							
						<p>These efforts reflect a recognition that existing research norms have failed to address the impacts of AI research <a href="https://medium.com/@CoalitionForCriticalTechnology/abolish-the-techtoprisonpipeline-9b5b14366b16">[7]</a> <a href="https://www.math-boycotts-police.net/">[8]</a> <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/microsofts-ai-research-draws-controversy-over-possible-disinformation-use">[9]</a> <a href="https://medium.com/@emilymenonbender/is-there-research-that-shouldnt-be-done-is-there-research-that-shouldn-t-be-encouraged-b1bf7d321bb6">[10]</a>, and take place against the backdrop of a larger reckoning with the role of AI in perpetuating injustice <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">[11]</a> <a href="https://science.sciencemag.org/content/366/6464/447">[12]</a> <a href="https://nyupress.org/9781479837243/algorithms-of-oppression/">[13]</a> <a href="https://www.ruhabenjamin.com/race-after-technology">[14]</a> <a href="https://mitpress.mit.edu/books/artificial-unintelligence">[15]</a>. The changes have been met with both praise and criticism <a href="https://venturebeat.com/2020/02/24/neurips-requires-ai-researchers-to-account-for-societal-impact-and-financial-conflicts-of-interest/">[16]</a> some within and outside the community see them as a crucial first step towards integrating ethical reflection and review into the research process, fostering necessary changes to protect populations at risk of harm. Others worry that AI researchers are not well placed to recognize and reason about the potential impacts of their work, as effective ethical deliberation may require different expertise and the involvement of other stakeholders.</p>
						
						<p>This debate reveals that even as the AI research community is beginning to grapple with the legitimacy of certain research questions and critically reflect on its research practices, there remains many open questions about how to ensure effective ethical oversight. This workshop therefore aims to examine how concerns with harmful impacts should affect the way the research community develops its research agendas, conducts its research, evaluates its research contributions, and handles the publication and dissemination of its findings. This event complements other NeurIPS workshops this year (e.g., <a href="https://sites.google.com/view/resistance-ai-neurips-20/home?authuser=0">[17]</a> <a href="https://research.yandex.com/workshops/crowd/neurips-2020">[18]</a>) devoted to normative issues in AI and builds on others from years past (e.g., <a href="https://sites.google.com/view/aiethicsworkshop">[19]</a> <a href="https://mindingthegap.github.io/">[20]</a> <a href="https://aiforsocialgood.github.io/neurips2019/">[21]</a>), but adopts a distinct focus on the ethics of <em>research</em> practice and the ethical obligations of <em>researchers</em>.</p>

				
					</article>
					

				</div>

				<div id="CFP" class="wrapper style1">

					<article id="main" class="container special">
						<!-- <a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a> -->
						<header>
							<h2>Call for Participation</h2>
							<p>
								The submission deadline has passed, it was <strong>October 12, 2020</strong>.
							</p>
						</header>
						<p>The workshop will include contributed papers. All accepted papers will be allocated either a virtual poster presentation or a virtual talk slot. Authors will have the option to have final versions of workshop papers and talk recordings linked on the workshop website.</p>
						<p>Submissions can be <strong>4 pages maximum</strong>, excluding references and supplementary materials, and formatted in the provided NeurIPS general submissions templates. Papers should not include any identifying information about the authors to allow for anonymous review. Previously published work (or work under review) is acceptable, with the exception of previously published machine learning research.</p>
							
						<p>We invite submissions relating to the role of the research community in navigating the broader impacts of AI research. Workshop paper submissions can include case studies, surveys, analyses, and position papers, including but not limited to the following topics:</p>

						<ul class="disc">
							<li>
								<strong>Mechanisms of ethical oversight in AI research:</strong> What are some of the <strong>practical mechanisms for anticipating future risks and mitigating harms</strong> caused by AI research? Are such practices actually effective in improving societal outcomes and protecting vulnerable populations? To what extent do they help in bridging the gap between AI researchers and those with other perspectives and expertise, including the populations at risk of harm?
									<ul class="disc">
										<li>
											Analysis of the strengths and limitations of the NeurIPS broader impact statement as a mechanism for ethical oversight
										</li>
										<li>
											Reflections on experiences with this year’s NeurIPS ethical oversight process
										</li>
										<li>
											Ideas for alternative ethical review procedures, including how such determinations should be made and who should be involved in these determinations <a href="https://fpf.org/wp-content/uploads/2019/10/DesigningAIResearchReviewCommittee.pdf">[22]</a>
										</li>
										<li>
											Assessments of the strengths and limitations of research ethics and institutional review boards <a href="https://doi.org/10.1177/2053951716650211">[23]</a>, particularly with respect to the formulation of research questions and the broader impact of research findings <a href="https://medium.com/pervade-team/the-study-has-been-approved-by-the-irb-gayface-ai-research-hype-and-the-pervasive-data-ethics-ed76171b882c">[24]</a>
										</li>
										<li>
											Examples of how other fields engaged in high-risk research have handled the issue of ethical oversight (e.g., nuclear energy, nanotechnology, synthetic biology, geoengineering, etc.)
										</li>
										<li>
											Lessons from research traditions that work directly with affected communities to develop research questions and research designs
										</li>
									</ul>
							</li>
							<li>
								<strong>Challenges of AI research practice and responsible publication:</strong> What <strong>practices</strong> are appropriate for the <strong>responsible development, conduct, and dissemination</strong> of AI research? How can we ensure wide-spread adoption?
									<ul class="disc">
										<li>
											Surveys of responsible research practice in AI research, including common practices around data collection, crowdsourced labeling, documentation and reporting requirements, declaration of conflict of interest, etc. <a href="https://sites.google.com/view/fatecv-tutorial/schedule?authuser=0)]">[25]</a> <a href="https://megapixels.cc/">[26]</a> <a href="https://ghostwork.info/">[27]</a> <a href="https://dl.acm.org/doi/abs/10.1145/2470654.2470742">[28]</a>
										</li>
										<li>
											Limitations and benefits of the conference-based publication format, peer review, and other characteristics of AI publication norms, including alternative proposals (e.g., gated or staged release) <a href="https://www.lawfareblog.com/artificial-intelligence-research-needs-responsible-publication-norms">[29]</a> <a href="http://arxiv.org/abs/1907.11274">[30]</a> <a href="http://arxiv.org/abs/2001.00463">[31]</a>
										</li>
									</ul>
							</li>
							<li>
								<strong>Collective and individual responsibility in AI research: Who is best placed to anticipate and address</strong> potential research impacts? What should be the <strong>role of AI researchers and the AI research community</strong>? And how do we get there? 
									<ul class="disc">
										<li>
											Discussions of the role and obligations of different stakeholders (e.g., conference organizers, institutions, funders, researchers, users/customers, etc.) in ensuring ethical reflection and anticipating impacts of AI research <a href="https://www.wired.com/story/ai-algorithms-need-drug-trials/">[32]</a>
										</li>
										<li>
											How does the lack of diversity in the AI research community contribute to the problem of overlooking or underestimating potential harms?
										</li>
										<li>
											Proposals for how to empower the impacted populations to shape research agendas, practices, and publication norms <a href="https://arxiv.org/abs/1912.07376">[33]</a>
										</li>
										<li>
											What makes for a quality ethical reflection? How can researchers prepare themselves for ethical reflection?
										</li>
										<li>
											How do the obligations of researchers and practitioners differ when considering the potential impacts of their work? Are there meaningful differences across research and applied contexts?
										</li>
										<li>
											Reflections on how ethical review could be integrated into different parts of the research pipeline, such as the funding process, IRB requirements, etc.
										</li>
								</ul>
							</li>
							<li>
								<strong>Anticipated risks and known harms of AI research:</strong> How should researchers <strong>identify the relevant risks</strong> posed by their work and what should be the different <strong>dimensions of concern</strong>? How can we ensure that researchers are well <strong>aware of known harms</strong> caused by related research and make sure that the field is <strong</strong>responsive to the needs and concerns of affected communities</strong>?
								<ul class="disc">
									<li>
										Examples of effective and ineffective mechanisms for identifying relevant risks, including ethical review of research proposals and pre-publication review <a href="http://arxiv.org/abs/1802.07228">[34]</a>
									</li>	
									<li>
										Proposals for creative approaches to understanding the impacts of research and prioritizing the protection of affected communities <a href="https://www.doteveryone.org.uk/project/consequence-scanning/">[35]</a> <a href="https://us.macmillan.com/books/9781250074317">[36]</a>
									</li>
									<li>
										Case studies of AI research that had harmful impacts
									</li>
									<li>
										Examples of AI research that had unanticipated consequences
									</li>
								</ul>
							</li>
						</ul>
						
						<p>Authors will be notified of acceptance by October 30, 2020.</p>

				
					</article>

				</div>

				<div id="Agenda" class="wrapper style1">

					<article id="main" class="container special">
						<!-- <a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a> -->
						<header>
							<h2>Agenda (Eastern Time)</h2>
							<p>
								Subject to change; speaker details coming soon
							</p>
						</header>
							<ul>
								<li>
									08:30 AM - 08:45 AM | Welcome
								</li>
								<li>
									08:45 AM - 09:15 AM | Keynote, Hanna Wallach (Microsoft)
								</li>
								<li>
									09:15 AM - 10:15 AM | Discussion panel: Ethical oversight in the peer review process 
								</li>
								<li>
									10:15 AM - 10:30 AM | Break
								</li>
								<li>
									10:30 AM - 11:30 AM | Discussion panel: Harms from AI research  
								</li>
								<li>
									11:30 AM - 12:30 PM | Discussion panel: Predictive Policing: Should researchers engage or blacklist?
								</li>
								<li>
									12:30 PM - 01:30 PM | Break: Lunch and watch lightning talks (in parallel) of accepted papers (Lightning talks are each 5-7 mins)
								</li>
								<li>
									01:30 PM - 02:30 PM | Parallel discussions with authors of submitted papers  
								</li>
								<li>
									02:30 PM - 03:30 PM | Discussion panel: Responsible publication: NLP case study  
								</li>
								<li>
									03:30 PM - 03:45 PM | Break
								</li>
								<li>
									03:45 PM - 04:45 PM | Discussion panel: Strategies for anticipating and mitigating risks  	
								</li>
								<li>
									04:45 PM - 05:45 PM | Discussion panel: The roles of different parts of the research ecosystem in navigating broader impacts
								</li>
								<li>
									05:45 PM - 06:00 PM | Closing remarks
								</li>
							</ul>	  
						
					</article>
	
				</div>
				<div id="Papers" class="wrapper style1">
	
					<article id="main" class="container special">
						<!-- <a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a> -->
						<header>
							<h2>Accepted Papers</h2>
						</header>
						<ul>
							<li>
								Auditing Government AI: Assessing ethical vulnerability of machine learning <i>(Alayna A Kennedy)</i>
							</li>
							<li>
								An Ethical Highlighter for People-Centric Dataset Creation <i>(Margot Hanley, Apoorv Khandelwal, Hadar Averbuch-Elor, Noah Snavely, Helen Nissenbaum)</i>
							</li>
							<li>
								The Managerial Effects of Algorithmic Fairness Activism <i>(Bo Cowgill, Fabrizio Dell'Acqua, Sandra Matz)</i>
							</li>
							<li>
								Biased Programmers? Or Biased Data? A Field Experiment in Operationalizing AI Ethics <i>(Bo Cowgill, Fabrizio Dell'Acqua, Augustin Chaintreau, Nakul Verma, Samuel Deng, Daniel Hsu)</i>
							</li>
							<li>
								Ethical Testing in the Real World: Recommendations for Physical Testing of Adversarial Machine Learning Attacks <i>(Ram Shankar Siva Kumar, Maggie Delano, Kendra Albert, Afsaneh Rigot, Jonathon Penney)</i>
							</li>
							<li>
								Nose to Glass: Looking In to Get Beyond <i>(Josephine Seah)</i>
							</li>
							<li>
								Training Ethically Responsible AI Researchers: a Case Study <i>(Hang Yuan, Claudia Vanea, Federica Lucivero, Nina Hallowell)</i>
							</li>
							<li>
								Like a Researcher Stating Broader Impact For the Very First Time <i>(Grace Abuhamad, Claudel Rheault)</i>
							</li>
							<li>
								Anticipatory Ethics and the Role of Uncertainty <i>(Priyanka Nanayakkara, Jessica Hullman, Nicholas Diakopoulos)</i>
							</li>
							<li>
								Non-Portability of Algorithmic Fairness in India <i>(Nithya Sambasivan, Erin Arnesen, Ben Hutchinson, Vinodkumar Prabhakaran)</i>
							</li>
							<li>
								An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process <i>(David Tran, Alex Valtchanov, Keshav R Ganapathy, Raymond Feng, Eric Slud, Micah Goldblum, Tom Goldstein)</i>
							</li>
							<li>
								AI in the “Real World”: Examining the Impact of AI Deployment in Low-Resource Contexts <i>(Chinasa T Okolo)</i>
							</li>
							<li>
								Ideal theory in AI ethics <i>(Daniel Estrada)</i>
							</li>
							<li>
								Overcoming Failures of Imagination in AI Infused System Development and Deployment <i>(Margarita Boyarskaya, Alexandra Olteanu, Kate Crawford, Solon Barocas)</i>
							</li>
						</ul>
						
					</article>
	
				</div>	

			<!-- People -->

			<section id="People" class="carousel" class="container special">
				<h2>Organizers</h2>

				<div class="reel">

					<header>
					<a href="mailto:rosie@partnershiponai.org">Contact us</a> if you have any questions about the workshop.
				</header>
					<article>
						<a href="https://www.fhi.ox.ac.uk/team/carolyn-ashurst/" class="image featured"><img src="images/Organizers/carolyn.png" alt="" /></a>
						<header>
							<h3><a href="https://www.fhi.ox.ac.uk/team/carolyn-ashurst/" target="_blank">Carolyn Ashurst</a></h3>
						</header>
						<p>Governance of AI,<br />Future of Humanity Institute</p>
					</article>

					<article>
						<a href="http://solon.barocas.org/" class="image featured"><img src="images/Organizers/solon.png" alt="" /></a>
						<header>
							<h3><a href="http://solon.barocas.org/" target="_blank">Solon Barocas</a></h3>
						</header>
						<p>Microsoft Research<br />Cornell University</p>
					</article>

					<article>
						<a href="https://www.linkedin.com/in/deborah-raji-065751b2" class="image featured"><img src="images/Organizers/deb.png" alt="" /></a>
						<header>
							<h3><a href="https://www.linkedin.com/in/deborah-raji-065751b2" target="_blank">Deb Raji</a></h3>
						</header>
						<p>Mozilla Foundation<br />&nbsp;</p>
					</article>

					<article>
						<a href="https://www.partnershiponai.org/team/rosie-campbell/" class="image featured"><img src="images/Organizers/rosie.png" alt="" /></a>
						<header>
							<h3><a href="https://www.partnershiponai.org/team/rosie-campbell/" target="_blank">Rosie Campbell</a></h3>
						</header>
						<p>Partnership on AI<br />&nbsp;</p>
					</article>

					<article>
						<a href="https://humancompatible.ai/people#stuart-russell" class="image featured"><img src="images/Organizers/stuart.png" alt="" /></a>
						<header>
							<h3><a href="https://humancompatible.ai/people#stuart-russell" target="_blank">Stuart Russell</a></h3>
						</header>
						<p>Center for Human-Compatible AI,<br />UC Berkeley</p>
					</article>

				</div>
			</section>
			<div id="PC" class="wrapper style1">

				<article id="main" class="container special">
				<header>
					<h2>Program Committee</h2>
				</header>
				<div class="parent">  
					<div class="left" style="text-align: center;">
						<ul>
							<li>Alex Hanna, Google</li>
						<li>Angus Galloway, University of Guelph</li>
						<li>Asia Biega, Microsoft Research</li>
						<li>Aviv Ovadya, Thoughtful Technology Project</li>
						<li>Bran Knowles, Lancaster University</li>
						<li>Carina Prunkl, University of Oxford</li>
						<li>Carolina Aguerre, Centre for Global Cooperation Research</li>
						<li>Casey Fiesler, University of Colorado</li>
						<li>David Robinson, Cornell University</li>
						<li>Gillian Hadfield, University of Toronto</li>
						<li>Grace Abuhamad, Element AI</li>
						<li>Jake Metcalf, Data and Society</li>
						<li>Jasmine Wang, Partnership on AI</li>
						<li>Karrie Karahalios, University of Illinois at Urbana-Champaign</li>
						<li>Kate Vredenburgh, London School of Economics</li>
						</ul>
					</div>
					<div class="right" style="text-align: center;">
						<ul>
						<li>Katie Shilton, University of Maryland</li>
						<li>Luke Stark, University of Western Ontario</li>
						<li>Malavika Jayaram, Harvard University</li>
						<li>Maria De-Arteaga, University of Texas at Austin</li>
						<li>Markus Anderljung, Oxford</li>
						<li>Matthew BUI, NYU</li>
						<li>McKane Andrus, Partnership on AI</li>
						<li>Michael Zimmer, Marquette</li>
						<li>Nyalleng Moorosi, Google</li>
						<li>Rumman Chowdhury, Accenture AI</li>
						<li>Seda Gürses, Delft</li>
						<li>Seth Lazar, Australian National University</li>
						<li>Stevie Chancellor, University of Minnesota</li>
						<li>Toby Shevlane, University of Oxford</li>
						<li>Zachary Lipton, Carnegie Mellon University</li>
					</ul>
				</div>
				  </div>  
				
				</article>
			</div>
			
			<!-- Features -->
				<!-- <div class="wrapper style1">

					<section id="features" class="container special">
						<header>
							<h2>Morbi ullamcorper et varius leo lacus</h2>
							<p>Ipsum volutpat consectetur orci metus consequat imperdiet duis integer semper magna.</p>
						</header>
						<div class="row">
							<article class="col-4 col-12-mobile special">
								<a href="#" class="image featured"><img src="images/pic07.jpg" alt="" /></a>
								<header>
									<h3><a href="#">Gravida aliquam penatibus</a></h3>
								</header>
								<p>
									Amet nullam fringilla nibh nulla convallis tique ante proin sociis accumsan lobortis. Auctor etiam
									porttitor phasellus tempus cubilia ultrices tempor sagittis. Nisl fermentum consequat integer interdum.
								</p>
							</article>
							<article class="col-4 col-12-mobile special">
								<a href="#" class="image featured"><img src="images/pic08.jpg" alt="" /></a>
								<header>
									<h3><a href="#">Sed quis rhoncus placerat</a></h3>
								</header>
								<p>
									Amet nullam fringilla nibh nulla convallis tique ante proin sociis accumsan lobortis. Auctor etiam
									porttitor phasellus tempus cubilia ultrices tempor sagittis. Nisl fermentum consequat integer interdum.
								</p>
							</article>
							<article class="col-4 col-12-mobile special">
								<a href="#" class="image featured"><img src="images/pic09.jpg" alt="" /></a>
								<header>
									<h3><a href="#">Magna laoreet et aliquam</a></h3>
								</header>
								<p>
									Amet nullam fringilla nibh nulla convallis tique ante proin sociis accumsan lobortis. Auctor etiam
									porttitor phasellus tempus cubilia ultrices tempor sagittis. Nisl fermentum consequat integer interdum.
								</p>
							</article>
						</div>
					</section>

				</div> -->

			<!-- Footer -->
				<div id="footer">
					<div class="container">
						<div class="row">

							<!-- Tweets -->
								<!-- <section class="col-4 col-12-mobile">
									<header>
										<h2 class="icon brands fa-twitter circled"><span class="label">Tweets</span></h2>
									</header>
									<ul class="divided">
										<li>
											<article class="tweet">
												Amet nullam fringilla nibh nulla convallis tique ante sociis accumsan.
												<span class="timestamp">5 minutes ago</span>
											</article>
										</li>
										<li>
											<article class="tweet">
												Hendrerit rutrum quisque.
												<span class="timestamp">30 minutes ago</span>
											</article>
										</li>
										<li>
											<article class="tweet">
												Curabitur donec nulla massa laoreet nibh. Lorem praesent montes.
												<span class="timestamp">3 hours ago</span>
											</article>
										</li>
										<li>
											<article class="tweet">
												Lacus natoque cras rhoncus curae dignissim ultricies. Convallis orci aliquet.
												<span class="timestamp">5 hours ago</span>
											</article>
										</li>
									</ul>
								</section> -->

							<!-- Posts -->
								<!-- <section class="col-4 col-12-mobile">
									<header>
										<h2 class="icon solid fa-file circled"><span class="label">Posts</span></h2>
									</header>
									<ul class="divided">
										<li>
											<article class="post stub">
												<header>
													<h3><a href="#">Nisl fermentum integer</a></h3>
												</header>
												<span class="timestamp">3 hours ago</span>
											</article>
										</li>
										<li>
											<article class="post stub">
												<header>
													<h3><a href="#">Phasellus portitor lorem</a></h3>
												</header>
												<span class="timestamp">6 hours ago</span>
											</article>
										</li>
										<li>
											<article class="post stub">
												<header>
													<h3><a href="#">Magna tempus consequat</a></h3>
												</header>
												<span class="timestamp">Yesterday</span>
											</article>
										</li>
										<li>
											<article class="post stub">
												<header>
													<h3><a href="#">Feugiat lorem ipsum</a></h3>
												</header>
												<span class="timestamp">2 days ago</span>
											</article>
										</li>
									</ul>
								</section> -->

							<!-- Photos -->
								<!-- <section class="col-4 col-12-mobile">
									<header>
										<h2 class="icon solid fa-camera circled"><span class="label">Photos</span></h2>
									</header>
									<div class="row gtr-25">
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic10.jpg" alt="" /></a>
										</div>
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic11.jpg" alt="" /></a>
										</div>
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic12.jpg" alt="" /></a>
										</div>
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic13.jpg" alt="" /></a>
										</div>
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic14.jpg" alt="" /></a>
										</div>
										<div class="col-6">
											<a href="#" class="image fit"><img src="images/pic15.jpg" alt="" /></a>
										</div>
									</div>
								</section> -->

						</div>
						<!-- <hr /> -->
						<div class="row">
							<div class="col-12">

								<!-- Contact -->
									<!-- <section class="contact">
										<header>
											<h3>Nisl turpis nascetur interdum?</h3>
										</header>
										<p>Urna nisl non quis interdum mus ornare ridiculus egestas ridiculus lobortis vivamus tempor aliquet.</p>
										<ul class="icons">
											<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
											<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
											<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
											<li><a href="#" class="icon brands fa-pinterest"><span class="label">Pinterest</span></a></li>
											<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
											<li><a href="#" class="icon brands fa-linkedin-in"><span class="label">Linkedin</span></a></li>
										</ul>
									</section> -->

								<!-- Copyright -->
									<div class="copyright">
										<ul class="menu">
											<li>&copy; Navigating the Broader Impacts of AI Research. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
										</ul>
									</div>

							</div>

						</div>
					</div>
				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
